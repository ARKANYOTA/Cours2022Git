# ChaineDeMarkov

## I) Vocabulaire

[1...]

Ce graphe a 5 sommets. On dit qu'il est <u>d'ordre 5</u> 

Il y a 2 arêtes reliées à &B&.  
On dit alors que <u>&B& est degré 2</u>

Il y a une arête reliant à &A& à &B&: on dit alors que &A& et &B& sont adjacents.  
&A& et &D& ne sont pas adjacents.

Quand tous les sommets sont adjacents &2& à &2&, on dit que le graphe est <u>complet</u>

&A-B-C& est une <u>chaine</u> de longeur 2  (3 en informatique)  
&A-B-C-A-B& est une aussi une chaine, malgré la répétition, et elle est de longeur 4 (5 en informatique)  

Quand chaque couple de sommet peut être relié par une chaine le graphe est dit <u>connexe</u>.  

[2...] Le graphe ci-contre est non connexe.

[3...] Le graphe ci-contre est <u>orienté</u>

[4...] Le graphe ci-contre est <u>pondéré</u>, Le nombre figurant sur l'arête s'appelle son <u>poids</u>.

 

## II) Matrice dadjacence

La <u>matrice d'adjacence</u> permet de décrire numériquement le graphe

[5...]

&M = ((0, 1, 1, 1), (0, 0, 0, 0), (1, 0, 0, 0), (0, 1, 0, 0))&

Si &M& est la matrice d'adjacence d'un graphe &M^n (n in NN^**)& est une matrice dont le terme &a_(ij)& représente le nombre de chemins de longeur &n& des sommet &i& au sommet &j&

## III) Chaines de Markov

Un <u>graphe probabiliste</u> est un graphe orienté et pondéré par des réels compris entre &0& et &1& tels que la somme des poids des arêtes issues de chaque sommet esst égale à &1&.

##### Exemple:

[6...] Ce graph peut être décrit par une <u>matrice de transition</u> 

&P = ((0, 0.1, 0.9), (0.3, 0.2, 0.5), (1, 0, 0))&

La somme des termes de chaques lignes est égal à &1&.

La <u>distribution<u> correspond au valeurs attribuées à chaque sommet du graphe.  
On l'écrit sous forme de matrice ligne.  
Si on note &Pi_n& la distribution à l'étape &n&, on a <span class="box">&Pi_(n+1) = Pi_n P&</span> et on a <span class="box">Pi_n = Pi_0 P^n</span>

Exemple: Si &Pi_0 = (3 5 2)& on a alors &A_0 = 3, B_0 = 5, C_0 = 2&

[7...]

Une distribution &Pi& est une <u>invariante& si elle vérifie &Pi P = Pi&
